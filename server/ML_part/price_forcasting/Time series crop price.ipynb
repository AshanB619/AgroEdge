{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50d440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d2adbfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Commodity</th>\n",
       "      <th>Market Region</th>\n",
       "      <th>Price per Unit (LKR/kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-13</td>\n",
       "      <td>Winged Bean</td>\n",
       "      <td>Ampara</td>\n",
       "      <td>376.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-13</td>\n",
       "      <td>Winged Bean</td>\n",
       "      <td>Anuradhapura</td>\n",
       "      <td>210.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-13</td>\n",
       "      <td>Winged Bean</td>\n",
       "      <td>Badulla</td>\n",
       "      <td>362.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-13</td>\n",
       "      <td>Winged Bean</td>\n",
       "      <td>Batticaloa</td>\n",
       "      <td>169.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-13</td>\n",
       "      <td>Winged Bean</td>\n",
       "      <td>Colombo</td>\n",
       "      <td>372.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date    Commodity Market Region  Price per Unit (LKR/kg)\n",
       "0 2020-02-13  Winged Bean        Ampara                   376.43\n",
       "1 2020-02-13  Winged Bean  Anuradhapura                   210.15\n",
       "2 2020-02-13  Winged Bean       Badulla                   362.29\n",
       "3 2020-02-13  Winged Bean    Batticaloa                   169.92\n",
       "4 2020-02-13  Winged Bean       Colombo                   372.34"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file path\n",
    "file_path = r\"C:\\Users\\user\\Desktop\\iit\\year2 sem1\\sdgp\\AgroEdge\\server\\ML_part\\price_forcasting\\vegetable_fruit_prices.xlsx\"\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Display the first few rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335eb9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599731d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing values in each column\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf14edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop exact duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "print(\"No of duplicates:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c320f690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the dates to date time format\n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8f3124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "Q1 = df['Price per Unit (LKR/kg)'].quantile(0.25)\n",
    "Q3 = df['Price per Unit (LKR/kg)'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define bounds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Find outliers\n",
    "outliers = df[(df['Price per Unit (LKR/kg)'] < lower_bound) | (df['Price per Unit (LKR/kg)'] > upper_bound)]\n",
    "print(\"Number of outliers:\", len(outliers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343de2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Commodity'] = df['Commodity'].str.strip().str.lower()\n",
    "df['Commodity'] = df['Commodity'].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b29699",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7812b586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1441e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Price Distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df['Price per Unit (LKR/kg)'], bins=50, kde=True)\n",
    "plt.title(\"Distribution of Prices\")\n",
    "plt.xlabel(\"Price per Unit (LKR/kg)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205592b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot for detecting outliers\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(x=df['Price per Unit (LKR/kg)'])\n",
    "plt.title(\"Boxplot of Prices (Outlier Detection)\")\n",
    "plt.xlabel(\"Price per Unit (LKR/kg)\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cc95b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series Plot for Average Price Trend\n",
    "df_avg_price = df.groupby(\"Date\")[\"Price per Unit (LKR/kg)\"].mean()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df_avg_price.index, df_avg_price.values, marker=\"o\", linestyle=\"-\", label=\"Average Price\")\n",
    "plt.title(\"Time Series Trend of Average Prices\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Average Price\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c33d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show unique crop and city counts\n",
    "unique_crops = df['Commodity'].nunique()\n",
    "unique_cities = df['Market Region'].nunique()\n",
    "\n",
    "# Display results\n",
    "unique_crops, unique_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb5de92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from IPython.display import display  \n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Encode categorical variables\n",
    "crop_encoder = LabelEncoder()\n",
    "city_encoder = LabelEncoder()\n",
    "\n",
    "df[\"Commodity_Encoded\"] = crop_encoder.fit_transform(df[\"Commodity\"])\n",
    "df[\"Market_Region_Encoded\"] = city_encoder.fit_transform(df[\"Market Region\"])\n",
    "\n",
    "# Drop original categorical columns\n",
    "df_encoded = df.drop(columns=[\"Commodity\", \"Market Region\"])\n",
    "\n",
    "# Display first few rows of the updated dataset\n",
    "display(df_encoded)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4e0e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the mapping for Commodity\n",
    "commodity_mapping = {index: value for index, value in enumerate(crop_encoder.classes_)}\n",
    "print(\"\\nCommodity Encoding Mapping:\")\n",
    "for key, val in commodity_mapping.items():\n",
    "    print(f\"{val} -> {key}\")\n",
    "\n",
    "# Retrieve the mapping for Market Region\n",
    "market_region_mapping = {index: value for index, value in enumerate(city_encoder.classes_)}\n",
    "print(\"\\nMarket Region Encoding Mapping:\")\n",
    "for key, val in market_region_mapping.items():\n",
    "    print(f\"{val} -> {key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cecab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Apply MinMaxScaler to price column\n",
    "scaler = MinMaxScaler()\n",
    "df[\"Price_Scaled\"] = scaler.fit_transform(df[[\"Price per Unit (LKR/kg)\"]])\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df_scaled = df.drop(columns=[\"Price per Unit (LKR/kg)\", \"Commodity\", \"Market Region\"])\n",
    "\n",
    "# Display the transformed dataset in Jupyter Notebook\n",
    "display(df_scaled)  # Use this in Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c64a8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller  # Import ADF test function\n",
    "\n",
    "# Reduce dataset size for ADF test (sampling 5000 records)\n",
    "sample_size = 5000\n",
    "df_sample = df.sample(n=sample_size, random_state=42)\n",
    "\n",
    "# Run ADF test on the sampled data\n",
    "adf_test_result = adfuller(df_sample[\"Price_Scaled\"])\n",
    "\n",
    "# Extract the p-value\n",
    "stationarity_p_value = adf_test_result[1]\n",
    "\n",
    "# Determine stationarity\n",
    "is_stationary = \"Stationary\" if stationarity_p_value < 0.05 else \"Non-Stationary\"\n",
    "\n",
    "# Display results\n",
    "print(f\"ADF Test p-value: {stationarity_p_value}\")\n",
    "print(f\"Dataset is: {is_stationary}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8c175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed = df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43aa241",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5f609d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b7f2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"Checking dataset...\")\n",
    "    print(df_preprocessed.head())  # Display first rows to confirm dataset is loaded\n",
    "except NameError:\n",
    "    print(\"Error: df_preprocessed is not defined. Load the dataset before running the model.\")\n",
    "    raise SystemExit\n",
    "\n",
    "# Print unique values for debugging\n",
    "print(\"Unique Commodities:\", df_preprocessed[\"Commodity_Encoded\"].unique())\n",
    "print(\"Unique Regions:\", df_preprocessed[\"Market_Region_Encoded\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709642e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_lstm_data(series, n_lags):\n",
    "    \"\"\"Prepare time series data for LSTM.\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(series) - n_lags):\n",
    "        X.append(series[i:i + n_lags])\n",
    "        y.append(series[i + n_lags])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35a2f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_commodity = 5  # Example: Change based on user selection (I added this just for cheking the input)\n",
    "selected_region = 12     # Example: Change based on user selection (I added this just for cheking the input)\n",
    "\n",
    "# Check if the selected commodity and region exist\n",
    "if selected_commodity not in df_preprocessed[\"Commodity_Encoded\"].unique():\n",
    "    raise ValueError(f\"Commodity {selected_commodity} not found in dataset.\")\n",
    "if selected_region not in df_preprocessed[\"Market_Region_Encoded\"].unique():\n",
    "    raise ValueError(f\"Region {selected_region} not found in dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4643e85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_preprocessed[\n",
    "    (df_preprocessed[\"Commodity_Encoded\"] == selected_commodity) & \n",
    "    (df_preprocessed[\"Market_Region_Encoded\"] == selected_region)\n",
    "]\n",
    "\n",
    "# Ensure the dataset is sorted by date\n",
    "df_filtered = df_filtered.sort_values(\"Date\")\n",
    "\n",
    "# Convert \"Date\" column to datetime format\n",
    "df_filtered[\"Date\"] = pd.to_datetime(df_filtered[\"Date\"])\n",
    "\n",
    "# Check if 'Price_Scaled' exists\n",
    "if \"Price_Scaled\" not in df_filtered.columns:\n",
    "    raise KeyError(\"Column 'Price_Scaled' not found in dataset.\")\n",
    "\n",
    "# Use 'Price_Scaled' as the target variable\n",
    "prices = df_filtered[\"Price_Scaled\"].values\n",
    "\n",
    "# Define the number of past weeks to consider for forecasting\n",
    "n_lags = 12  # Using past 12 weeks to predict the next 12 weeks\n",
    "\n",
    "# Prepare input features and target labels\n",
    "X, y = prepare_lstm_data(prices, n_lags)\n",
    "\n",
    "# Check for empty arrays\n",
    "if len(X) == 0 or len(y) == 0:\n",
    "    raise ValueError(\"Not enough data points available for training. Try selecting a different commodity or region.\")\n",
    "\n",
    "# Reshape for LSTM (samples, time steps, features)\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeec0aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Check shapes before training\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1475e132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# Define Callbacks (Learning Rate Scheduler & Early Stopping)\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss',  # Reduce LR if val_loss plateaus\n",
    "    factor=0.5,  \n",
    "    patience=5,  \n",
    "    min_lr=1e-6  \n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Stop training if val_loss doesn't improve\n",
    "    patience=10,  \n",
    "    restore_best_weights=True  # Restore best weights when stopping\n",
    ")\n",
    "\n",
    "# Final Optimized Model\n",
    "model = Sequential([\n",
    "    Input(shape=(n_lags, 1)),  # Fix input shape warning\n",
    "    LSTM(128, activation='relu', return_sequences=True),  # Increased LSTM units (from 64 → 128)\n",
    "    Dropout(0.15),  \n",
    "    LSTM(128, activation='relu'),  \n",
    "    Dropout(0.15),\n",
    "    Dense(1)  \n",
    "])\n",
    "\n",
    "#  Compile Model with Adjusted Learning Rate\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005), loss='mse')\n",
    "\n",
    "#  Train Model with Callbacks\n",
    "history = model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=100,  # Let early stopping decide actual stopping point\n",
    "    batch_size=32,  \n",
    "    validation_data=(X_test, y_test),  \n",
    "    verbose=1,  \n",
    "    callbacks=[lr_scheduler, early_stopping]  # Include both optimizations\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
